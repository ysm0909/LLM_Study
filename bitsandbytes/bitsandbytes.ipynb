{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4e91cb-444d-4332-bac6-64f8ba24aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import bitsandbytes\n",
    "from bitsandbytes.nn import Linear8bitLt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c47d63-73f0-403c-8932-b332494bc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fp16 model\n",
    "fp16_model = nn.Sequential(\n",
    "    nn.Linear(64, 64),\n",
    "    nn.Linear(64, 64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb92931-2900-46a4-adcd-28d98e83419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the model has been trained\n",
    "torch.save(fp16_model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92482552-f4c8-4fb1-a720-de301c5acbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an int8 model\n",
    "int8_model = nn.Sequential(\n",
    "    Linear8bitLt(64, 64, has_fp16_weights=False), # important to add the flag \"has_fp16_weights\"  \n",
    "    Linear8bitLt(64, 64, has_fp16_weights=False)  # has_fp16_weights = True: 혼합 정밀도(mixed precision),Int8와 FP16을 섞어서 학습(training) 할 때 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ad6323-d1bd-4194-9ea4-d96a30affff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "Parameter(Int8Params([[ 0.0177, -0.1196, -0.0731,  ..., -0.0559,  0.1001, -0.0698],\n",
       "            [ 0.0621, -0.0373, -0.0265,  ...,  0.0484,  0.0413, -0.0669],\n",
       "            [ 0.0821, -0.0486,  0.0993,  ..., -0.0769,  0.0651, -0.0104],\n",
       "            ...,\n",
       "            [-0.0200, -0.0156,  0.0902,  ..., -0.1025, -0.0956, -0.1116],\n",
       "            [-0.1015,  0.0990,  0.1098,  ..., -0.0298, -0.0594, -0.0190],\n",
       "            [-0.0742,  0.0241,  0.0710,  ...,  0.0275,  0.0411, -0.0178]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before calling the .to function\n",
    "int8_model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7408dea-3021-49fe-8933-adb2b011e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model in 8-bit\n",
    "int8_model.load_state_dict(torch.load(\"model.pt\"))\n",
    "int8_model = int8_model.to(0) # Quantization happens here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "202ea51f-00ca-445b-8357-62f67e8f88d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "Parameter(Int8Params([[  73,  116,   60,  ...,   95,   89,   -3],\n",
       "            [ -58,  -13,   60,  ...,   38,   27,   32],\n",
       "            [ -43,  -82,   76,  ...,  -77,  -40,   -7],\n",
       "            ...,\n",
       "            [ -65,   66,   10,  ..., -125,    2,  -38],\n",
       "            [-127,  -20,  -23,  ..., -106,   75, -110],\n",
       "            [  21,  -45,   89,  ...,   20, -125, -100]], device='cuda:0',\n",
       "           dtype=torch.int8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int8_model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd349ac-a7e7-4025-833c-052bdf9ade75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0697,  0.1136,  0.0580,  ...,  0.0924,  0.0871, -0.0029],\n",
       "        [-0.0554, -0.0127,  0.0580,  ...,  0.0369,  0.0264,  0.0310],\n",
       "        [-0.0411, -0.0803,  0.0735,  ..., -0.0749, -0.0392, -0.0068],\n",
       "        ...,\n",
       "        [-0.0621,  0.0646,  0.0097,  ..., -0.1215,  0.0020, -0.0368],\n",
       "        [-0.1213, -0.0196, -0.0223,  ..., -0.1031,  0.0734, -0.1064],\n",
       "        [ 0.0201, -0.0441,  0.0861,  ...,  0.0194, -0.1224, -0.0967]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to retrieve the FP16 weight in order to perform the outlier MatMul in fp16?\n",
    "(int8_model[0].weight.CB * int8_model[0].weight.SCB) / 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ca4ea4-eba8-4151-af28-d6ebb49e767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer using the model\n",
    "input_ = torch.randn((1, 64), dtype=torch.float16)\n",
    "hidden_states = int8_model(input_.to(torch.device('cuda', 0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamatest",
   "language": "python",
   "name": "llamatest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
